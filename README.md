# ğŸ§  DetecciÃ³n de Espasticidad Infantil mediante Machine Learning

> *Porque cada segundo cuenta en el diagnÃ³stico temprano*

Este proyecto nace de una idea simple pero poderosa: **utilizar la inteligencia artificial para ayudar a detectar espasticidad en bebÃ©s de forma temprana**, cuando la intervenciÃ³n terapÃ©utica puede marcar la diferencia entre una vida con limitaciones y un desarrollo pleno.

## ğŸ¯ Â¿Por quÃ© este proyecto?

La espasticidad infantil es una condiciÃ³n que afecta el control muscular en niÃ±os pequeÃ±os. Un diagnÃ³stico tardÃ­o puede significar perder la ventana crÃ­tica de neuroplasticidad, ese perÃ­odo mÃ¡gico donde el cerebro infantil tiene una capacidad extraordinaria de adaptaciÃ³n.

Este sistema analiza **videos de movimientos espontÃ¡neos** de bebÃ©s y, mediante tÃ©cnicas de Machine Learning, identifica patrones que pueden indicar riesgo de espasticidad. 

## ğŸ› ï¸ Â¿CÃ³mo funciona?

```
Video del bebÃ© â†’ ExtracciÃ³n de caracterÃ­sticas â†’ Modelo ML â†’ PredicciÃ³n de riesgo
```

El pipeline combina tres tipos de anÃ¡lisis:

- **Flujo Ã³ptico**: Detecta cÃ³mo se mueve el bebÃ© frame a frame
- **CaracterÃ­sticas temporales**: Analiza la dinÃ¡mica del movimiento a lo largo del tiempo
- **CaracterÃ­sticas espaciales**: Estudia la distribuciÃ³n del movimiento en diferentes partes del cuerpo

Cuatro modelos trabajan en conjunto para ofrecer predicciones robustas: 
- RegresiÃ³n LogÃ­stica
- Random Forest
- SVM (Support Vector Machine)
- XGBoost

## ğŸ“‹ Requisitos

```bash
# Clonar el repositorio
git clone https://github.com/maximofernandezriera/ML-deteccion-espasticidad-infantil.git
cd ML-deteccion-espasticidad-infantil

# Crear entorno virtual (recomendado)
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

**Dependencias principales**:  NumPy, Pandas, Scikit-learn, XGBoost, OpenCV, SHAP

## ğŸš€ Uso

```bash
# Ejecutar el pipeline completo
python main_pipeline.py
```

El sistema generarÃ¡: 
- Modelos entrenados en `/models`
- Reportes de evaluaciÃ³n en `/reports`
- Visualizaciones explicativas con SHAP

## ğŸ“ Estructura del proyecto

```
â”œâ”€â”€ main_pipeline.py          # Pipeline principal
â”œâ”€â”€ config.yaml               # ConfiguraciÃ³n centralizada
â”œâ”€â”€ exportar_videos_npz.py    # Utilidad para exportar videos
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                 # Carga y divisiÃ³n de datos
â”‚   â”œâ”€â”€ features/             # ExtracciÃ³n de caracterÃ­sticas
â”‚   â”œâ”€â”€ models/               # ImplementaciÃ³n de modelos
â”‚   â”œâ”€â”€ evaluation/           # MÃ©tricas clÃ­nicas
â”‚   â””â”€â”€ explainability/       # AnÃ¡lisis SHAP
â””â”€â”€ requirements.txt
```

## ğŸ“Š MÃ©tricas de evaluaciÃ³n

El sistema prioriza mÃ©tricas clÃ­nicamente relevantes:
- **Sensibilidad â‰¥ 90%**: Minimizar falsos negativos (no pasar por alto casos reales)
- **AUC-ROC â‰¥ 85%**: Capacidad discriminativa general
- **Especificidad â‰¥ 75%**:  Reducir falsos positivos

## ğŸ”¬ Interpretabilidad

No nos conformamos con un modelo "caja negra". Mediante **SHAP (SHapley Additive exPlanations)**, cada predicciÃ³n viene acompaÃ±ada de una explicaciÃ³n visual de quÃ© caracterÃ­sticas influyeron en el resultado.

## ğŸ‘¨â€ğŸ“ Contexto acadÃ©mico

Este proyecto forma parte de un **Trabajo de Fin de MÃ¡ster (TFM)** en la Universitat Oberta de Catalunya (UOC), desarrollado por MÃ¡ximo FernÃ¡ndez Riera. 

## ğŸ“„ Licencia

Este proyecto estÃ¡ disponible como cÃ³digo abierto para fines educativos y de investigaciÃ³n.

---

*"La tecnologÃ­a al servicio de los mÃ¡s pequeÃ±os"* ğŸ’™